{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Gerrymandering-Environment**\n",
        "\n",
        "    INITIAL STATE (provided externally via reset(options=...)):\n",
        "        - 'district_map'\n",
        "        - 'social_graph'\n",
        "        - 'opinions'     \n",
        "\n",
        "    ACTION:\n",
        "        - new district assignment for each voter\n",
        "\n",
        "    OBSERVATION (returned by reset/step):\n",
        "        {\n",
        "          'district_map'   : (num_voters,)\n",
        "          'representatives': (num_districts,)  # voter indices; -1 if empty district\n",
        "          'social_graph'   : (num_voters, num_voters)  # AUGMENTED: base social + rep->voter edges used for the step\n",
        "          'opinions'       : (num_voters, 2)\n",
        "          'opinion_graph'  : (num_voters, num_voters)  # similarity kernel derived from opinion distances\n",
        "        }\n",
        "\n",
        "    KEY LOGIC:\n",
        "      - Representatives: for each district, pick the member that minimizes the sum of L2 distances to members in that district (discrete 1-median).\n",
        "      - Opinion dynamics: DRF (assimilation/neutral/backfire) with weighted neighbor influence.\n",
        "      - Reward: reduction in total distance to reference opinion c*\n",
        "\n",
        "    Notes:\n",
        "      - Opinion weight = 1\n",
        "      - Opinion dimension is fixed at 2.\n",
        "      - We accept any districting action"
      ],
      "metadata": {
        "id": "YVPu0WeaABON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7PJyuKxNG26",
        "outputId": "77494451-5681-42ce-84df-85046487ad4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import gerry_environment"
      ],
      "metadata": {
        "id": "ErlKBfKcRnP7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SVTh7C79jybC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulated_annealing_baseline(env, num_iterations=500, initial_beta=0.1, cooling_rate=1.01, rng=None):\n",
        "    if rng is None:\n",
        "        rng = np.random.default_rng()\n",
        "\n",
        "    # Get the current state (opinions) from the environment\n",
        "    current_opinions = env._x\n",
        "\n",
        "    # Initialize a random valid assignment\n",
        "    current_assignment = np.eye(env.num_districts)[rng.integers(0, env.num_districts, size=env.num_voters)]\n",
        "    current_assignment = env._ensure_non_empty(current_assignment)\n",
        "\n",
        "    # Evaluate the initial assignment\n",
        "    current_y = current_assignment.argmax(axis=1)\n",
        "    reps = env._elect_representatives_from_labels(current_y, current_opinions)\n",
        "    edge_index_aug, edge_attr_aug = env._augment_with_reps(env._edge_index, env._edge_attr, reps, current_y)\n",
        "    x_new = env._opinion_update(edge_index_aug, edge_attr_aug, current_opinions)\n",
        "    current_reward = env._reward(current_opinions, x_new)\n",
        "\n",
        "    # Track the best assignment found during the entire search\n",
        "    best_assignment = current_assignment.copy()\n",
        "    best_reward = current_reward\n",
        "\n",
        "    beta = initial_beta\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        # 1. Propose a new assignment (single-voter reassignment)\n",
        "        proposal_assignment = current_assignment.copy()\n",
        "        voter = rng.integers(0, env.num_voters)\n",
        "        new_d = rng.integers(0, env.num_districts)\n",
        "        proposal_assignment[voter, :] = 0\n",
        "        proposal_assignment[voter, new_d] = 1.0\n",
        "        proposal_assignment = env._ensure_non_empty(proposal_assignment)\n",
        "\n",
        "        # 2. Evaluate the proposal\n",
        "        proposal_y = proposal_assignment.argmax(axis=1)\n",
        "        reps = env._elect_representatives_from_labels(proposal_y, current_opinions)\n",
        "        edge_index_aug, edge_attr_aug = env._augment_with_reps(env._edge_index, env._edge_attr, reps, proposal_y)\n",
        "        x_new = env._opinion_update(edge_index_aug, edge_attr_aug, current_opinions)\n",
        "        proposal_reward = env._reward(current_opinions, x_new)\n",
        "\n",
        "        # 3. Metropolis-Hastings Acceptance Rule\n",
        "        if proposal_reward > current_reward:\n",
        "            # Always accept a better proposal\n",
        "            current_assignment = proposal_assignment\n",
        "            current_reward = proposal_reward\n",
        "        else:\n",
        "            # Accept a worse proposal with a probability\n",
        "            acceptance_prob = np.exp(beta * (proposal_reward - current_reward))\n",
        "            if rng.random() < acceptance_prob:\n",
        "                current_assignment = proposal_assignment\n",
        "                current_reward = proposal_reward\n",
        "\n",
        "        # 4. Update the best assignment found so far\n",
        "        if current_reward > best_reward:\n",
        "            best_assignment = current_assignment.copy()\n",
        "            best_reward = current_reward\n",
        "\n",
        "        # 5. Annealing: Increase beta over time (cool the system)\n",
        "        beta *= cooling_rate\n",
        "\n",
        "    return best_assignment, best_reward"
      ],
      "metadata": {
        "id": "xeTotQyStnh2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GXLeossttp_K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_voters = 10\n",
        "num_districts = 8\n",
        "T = 8\n",
        "triple_size = 3\n",
        "opinion_dim = 1\n",
        "\n",
        "opinions = np.zeros((num_voters, opinion_dim))\n",
        "opinions[:, 0] = np.linspace(-1, 1, num_voters)\n",
        "\n",
        "pos = np.arange(num_voters)[:,None]\n",
        "pos = np.hstack([pos, np.zeros_like(pos)])\n",
        "edges = [(i,i+1) for i in range(num_voters-1)]\n",
        "edge_index = np.array(edges + [(j,i) for i,j in edges]).T\n",
        "edge_attr = np.ones(edge_index.shape[1])\n",
        "\n",
        "env = gerry_environment.FrankenmanderingEnv(num_voters, num_districts, opinion_dim, horizon=T)\n",
        "\n",
        "obs, _ = env.reset(options={\n",
        "    \"opinions\": opinions,\n",
        "    \"pos\": pos,\n",
        "    \"edge_index\": edge_index,\n",
        "    \"edge_attr\": edge_attr\n",
        "})"
      ],
      "metadata": {
        "id": "vdqo0LSLlnDY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(T):\n",
        "    # Run MCMC/SA to find the best assignment given the current state\n",
        "    best_assignment, best_reward = simulated_annealing_baseline(\n",
        "        env,\n",
        "        num_iterations=2000,\n",
        "        initial_beta=0.1,\n",
        "        cooling_rate=1.001\n",
        "    )\n",
        "\n",
        "    # Apply this assignment in the environment\n",
        "    obs, reward, done, _, _ = env.step(best_assignment)\n",
        "\n",
        "    # Immediately run MCMC again on the new state to \"check\" or refine\n",
        "    refined_assignment, refined_reward = simulated_annealing_baseline(\n",
        "        env,\n",
        "        num_iterations=1000,\n",
        "        initial_beta=0.1,\n",
        "        cooling_rate=1.001\n",
        "    )\n",
        "\n",
        "    # (Optional) Replace with refined assignment if itâ€™s better\n",
        "    if refined_reward > reward:\n",
        "        obs, reward, done, _, _ = env.step(refined_assignment)\n",
        "\n",
        "    print(f\"t={t}, reward={reward:.3f}, mean opinion={obs.x.mean(0)}\")\n",
        "\n",
        "    if done:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Q1PwrLj5tsux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e6e768-52ad-4ae2-a5ef-a1ea18e77f7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=0, reward=3.111, mean opinion=tensor([-1.1921e-08])\n",
            "t=1, reward=-0.222, mean opinion=tensor([0.])\n",
            "t=2, reward=0.889, mean opinion=tensor([-0.2000])\n",
            "t=3, reward=0.444, mean opinion=tensor([0.])\n",
            "t=4, reward=-0.889, mean opinion=tensor([-0.2000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZUFwUxDZTwa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WodxaFwvuRMu"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}