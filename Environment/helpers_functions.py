# -*- coding: utf-8 -*-
"""Helpers_functions_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ueVUsFbEPFHIml29nk0s_I0S1H8Ugkp1
"""



import numpy as np
import torch
import copy
from typing import Optional, Tuple, Dict, Any
import math

# def labels_to_action(labels, num_districts, dtype=np.float32):
#     """
#     Convert an integer label vector (shape [N]) to an action matrix
#     expected by env.step: shape (N, num_districts), each row is
#     a 1-hot encoding of the desired district for that voter.
#     """
#     N = len(labels)
#     A = torch.zeros(N, num_districts)
#     for i, lab in enumerate(labels):
#         if lab >= 0 and lab < num_districts:
#             A[i, int(lab)] = 1.0
#         else:
#             # keep row zeros -> will become -1 label in env.step (avoid if possible)
#             pass
#     return A

# def row_normalize(A, eps=1e-8):
#         # A = np.array(A)

#         row_sum = torch.sum(A)
#         row_sum = torch.clamp(row_sum, eps, None)
#         return A / row_sum

# def row_normalize(A, eps=1e-8):
#   min = A.min()
#   max = A.max()

#   normalized = (A-min) / (max-min+eps)
#   return normalized


# def adj_to_coo(adj: np.ndarray):
#         row, col = np.nonzero(adj)
#         edge_index = np.vstack([row, col])
#         edge_attr = adj[row, col]
#         return edge_index, edge_attr

# normal = row_normalize(m)
# normal

"""**Elect representatives**
###This function elects representative in each district using a spatial / metric voting rule, specifically the median voter rule

```
Args:
        y: (N,) array of district labels for each voter.
        X: (N, opinion_dim) array of voter opinions.
        num_districts: number of districts (K).

    Returns:
        reps: list of representative indices, one per district (None if district empty)
```


"""

import numpy as np

def elect_representatives(dist_label, opinion, num_districts: int):

    reps = [None] * num_districts
    N, m = opinion.shape
    # Precompute pairwise distances
    dif = opinion[:, None, :] - opinion[None, :, :]   # (N,N,m)
    dists = torch.linalg.norm(dif, axis=2)   # (N,N) Euclidean distances

    for d in range(num_districts):
        members = torch.where(dist_label == d)[0]  # voters in district d
        if len(members) == 0:
            continue  # empty district

        # For each member, compute sum of distances to others in district
        sums = dists[members[:, None], members].sum(dim=1)
        # Pick the member with the minimal total distance/it stores the index of opinion
        reps[d] = int(members[torch.argmin(sums)])
    return reps

"""## **Augment with reps (G union H)**

###
Augment the social graph with representative edges (district graphs).
    
    Args:
        edge_index: (2, E) numpy array of existing social edges.
        edge_attr: (E,) numpy array of edge weights.
        reps: list of representative indices, one per district (None if empty).
        y: (N,) array of district assignments (each voter’s district label).
        rep_edge_weight: weight to assign to each representative edge (default=1.0).
    
    Returns:
        new_edge_index: (2, E+E_rep) with representative edges added.
        new_edge_attr:  (E+E_rep,) with weights for representative edges.
"""

def augment_with_reps(edge_index, edge_attr, reps, dist_label, rep_edge_weight: float = 1.0):

    add_src, add_dst, add_w = [], [], []
    existing = set(map(tuple, edge_index.T))

    for d, r in enumerate(reps):
        if r is None:
            continue  # empty district
        members = torch.where(dist_label == d)[0]

        for v in members:
            if v == r:
                continue  # skip self-loop

            if (r, v) in existing:
              continue  # skip duplicate

            add_src.append(r)             # representative -> member
            add_dst.append(v)
            add_w.append(rep_edge_weight) # fixed influence weight

    if not add_src:  # no additional edges
        return edge_index, edge_attr

    print('add_src',add_src)
    print('add_dst',add_dst)
    rep_edges = torch.vstack([add_src, add_dst])      # shape (2, E_rep)
    rep_weights = add_w

    new_edge_index = torch.cat([edge_index, rep_edges], axis=1)
    new_edge_attr  = torch.cat([edge_attr, rep_weights], axis=0)

    return new_edge_index, new_edge_attr

"""### **Opinion Update Function**
### At each step, voters "adjust" their position in opinion space based on the Euclidean distance to their neighbours, with the DRF


deciding whether they converge, diverge, or ignore.

Each neighbour "pulls" or "pushes" v depending on how similar they are.

The closer they are, the more v tends to assimilate.

If they’re a bit too far, v resists and moves in the opposite direction (backfire).

If they’re too far away, v ignores them.

The update is multi-dimensional, so if opinions are about multiple issues, the shift happens along the direction where the neighbour differs most.

Because normalization is used, v doesn’t "overreact" to having many neighbours.

    Apply opinion update based on DRF across graph edges.
    X: (N, opinion_dim)
    edge_index (augmented social graph): shape (2, E)
    edge_attr(w): shape (E,)
    mu : μ(∥cut​−cvt​∥)
"""

def opinion_update(edge_index_aug, edge_attr, opinion,drf):
    N, m = opinion.shape   # N voters, m-dimensional opinions
    newX = torch.zeros_like(opinion)

    updates = torch.zeros_like(opinion)
    norm_factors = torch.zeros((N, 1)) #Z

    for e in range(edge_index_aug.shape[1]):
        u, v = edge_index_aug[:, e]
        w = edge_attr[e]

        diff = opinion[u] - opinion[v]               # vector difference in opinion space

       # Euclidean distance
       # if diff is a 1-D array [x, y, z], then np.linalg.norm(diff, 2) calculates sqrt(x^2 + y^2 + z^2)
        dist = torch.linalg.norm(diff, 2)

        if dist > 1e-8:
            mu = drf(dist)

            direction = diff / dist    # unit vector (direction only)

            # influence: u influences v
            updates[v] += mu * w * direction
            norm_factors[v] += abs(w)

    # apply updates with normalization
    for v in range(N):
        if norm_factors[v] > 0:
            newX[v] = opinion[v] + updates[v] / norm_factors[v]

    return newX

"""**Discrepancy Response Function**
*   This function determines how a voter reacts when interacting with another voter based on the discrepancy (distance) between their opinions.
*   Tunable thresholds: epsilon values determine assimilation/backfire ranges. There are 5 levels in this range

### thresholds (tune these as hyperparameters)
*   eps_indiff = 0.5    below this = indifference
*   eps_backfire = 4.0  backfire zone
*   eps_irrel = 6.0     above this = irrelevance    
*   eps_assim = 2.0     assimilation zone

## **Population equality**
###(districts must have nearly equal populations)
Compute population deviation score.
    
    population weight: np.ndarray shape (N,) -> population of each voter/node
    labels: np.ndarray shape (N,) -> district assignment
    num_districts: int
    
    Returns: float (sum of deviations from ideal)
    '''
    Returns normalized population deviation:
      sum(|pop_d - ideal|) / total_pop
    This is in [0, 2*(1 - 1/num_districts)] roughly; smaller is better.
    '''
"""

def population_equality(pop_weights, dist_label, num_districts):

    pop_per = torch.zeros(num_districts, dtype=pop_weights.dtype, device=pop_weights.device)
    for d in range(num_districts):
        pop_per[d] = pop_weights[dist_label == d].sum()
    ideal = pop_per.mean()
    pop_dev = np.abs(pop_per - ideal).sum() / (ideal * num_districts)
    return pop_dev

"""## **check contiguity**
###A district is contiguous if all its members are connected to each other in the graph.
This function Check whether each district forms a connected component.
    
    edge_index: np.ndarray shape (2, E) -> edges
    labels: np.ndarray shape (N,) -> district assignment of each node
    num_districts: int
    
    Returns: bool (True if all districts are contiguous)

## **compactness score**
###  Compactness means districts should not be “spread out” with too many edges crossing between districts.This function computes compactness as ratio of cut edges to total edges.
    
    edge_index (social connection): np.ndarray shape (2, E)
    labels (district labels): np.ndarray shape (N,)
    
    Returns: float (compactness score)
"""

import torch

def compactness_score(geo_edge, dist_label) -> float:
    """
    Compute compactness score = (# of cut edges) / (total edges)
    based on the paper's definition.

    Args:
        geo_edge: torch.Tensor of shape (2, E), each column = (u, v)
        dist_label: torch.Tensor of shape (N,), district label for each node

    Returns:
        float: compactness score between 0 (most compact) and 1 (least compact)
    """
    # Extract endpoints of edges
    u = geo_edge[0]
    v = geo_edge[1]

    # Identify "cut edges" — edges connecting different districts
    cut_edges = (dist_label[u] != dist_label[v])
    num_cut_edges = cut_edges.sum()     # total number of boundary edges
    total_edges = cut_edges.size
    # num_cut_edges = cut_edges.sum().item()     # total number of boundary edges
    # total_edges = cut_edges.numel()             # total number of edges

    score = num_cut_edges/ total_edges
    return score

def drf_f1(discrepancy):
    delta = abs(discrepancy)

    if 0 <= delta <=1 :
        return 0  # indifference

    elif 1 < delta <= 2:
        return delta-1 # assimilation (y = x-1)

    elif 2 < delta <= 3:
        return 1 # assimilation (y = 1)

    elif 3 < delta <= 3.2:
        return -2*delta + 7 # assimilation (y=−2x+7)

    elif 3.2 < delta < 4:
        return 0  # ambivalence

    elif 4 <= delta < 5:
        return -1  # backfire

    elif 5 <= delta < 6:
        return  delta - 6 # backfire

    elif 6 <= delta  :
        return 0  # irrelevance (ignored)

def drf_inchworm_withso(discrepancy):
    delta = abs(discrepancy)

    if 0 <= delta < 2:
        return 0  # indifference

    elif 2 <= delta < 4:
        return 1  # assimilation (pull closer)

    elif 4 <= delta < 6:
        return -1  # backfire (push away)

    elif 6 <= delta  :
        return 0  # irrelevance (ignored)

    elif delta <= 2:
        return 0  # ambivalence

def drf_inc_noso(discrepancy):
    delta = abs(discrepancy)

    if 0 == delta:
        return 0  # indifference

    elif 0 < delta < 3:
        return 1  # assimilation (pull closer)

    elif 3 <= delta < 10:
        return -1  # backfire (push away)

    elif 10 <= delta  :
        return 0  # irrelevance (ignored)

    elif delta == 0:
        return 0  # ambivalence