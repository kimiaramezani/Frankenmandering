{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Gerrymandering-Environment**\n",
        "\n",
        "    INITIAL STATE (provided externally via reset(options=...)):\n",
        "        - 'district_map'\n",
        "        - 'social_graph'\n",
        "        - 'opinions'     \n",
        "\n",
        "    ACTION:\n",
        "        - new district assignment for each voter\n",
        "\n",
        "    OBSERVATION (returned by reset/step):\n",
        "        {\n",
        "          'district_map'   : (num_voters,)\n",
        "          'representatives': (num_districts,)  # voter indices; -1 if empty district\n",
        "          'social_graph'   : (num_voters, num_voters)  # AUGMENTED: base social + rep->voter edges used for the step\n",
        "          'opinions'       : (num_voters, 2)\n",
        "          'opinion_graph'  : (num_voters, num_voters)  # similarity kernel derived from opinion distances\n",
        "        }\n",
        "\n",
        "    KEY LOGIC:\n",
        "      - Representatives: for each district, pick the member that minimizes the sum of L2 distances to members in that district (discrete 1-median).\n",
        "      - Opinion dynamics: DRF (assimilation/neutral/backfire) with weighted neighbor influence.\n",
        "      - Reward: reduction in total distance to reference opinion c*\n",
        "\n",
        "    Notes:\n",
        "      - Opinion weight = 1\n",
        "      - Opinion dimension is fixed at 2.\n",
        "      - We accept any districting action"
      ],
      "metadata": {
        "id": "YVPu0WeaABON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7PJyuKxNG26",
        "outputId": "1c89fb9b-52da-4be3-f792-793ec10f6918"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces"
      ],
      "metadata": {
        "id": "ErlKBfKcRnP7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrankenmanderingEnv(gym.Env):\n",
        "    metadata = {\"render_modes\": [\"human\"]}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_voters: int,\n",
        "        num_districts: int,\n",
        "        opinion_dim: int = 2,\n",
        "        horizon: int = 10,\n",
        "        seed: int | None = None,\n",
        "\n",
        "        # opinion dynamics\n",
        "        eta: float = 0.2,\n",
        "        a_thresh: float = 0.4,\n",
        "        b_thresh: float = 1.2,\n",
        "        mu_assim: float = 1.0,\n",
        "        mu_backfire: float = -0.5,\n",
        "\n",
        "        # representative influence\n",
        "        rep_edge_weight: float = 1.0,\n",
        "\n",
        "        # reward target\n",
        "        reference_opinion: np.ndarray | None = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_voters = int(num_voters)\n",
        "        self.num_districts = int(num_districts)\n",
        "        self.opinion_dim = int(opinion_dim)\n",
        "        self.horizon = int(horizon)\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "\n",
        "        # dynamics params\n",
        "        self.eta = float(eta)\n",
        "        self.a_thresh = float(a_thresh)\n",
        "        self.b_thresh = float(b_thresh)\n",
        "        self.mu_assim = float(mu_assim)\n",
        "        self.mu_backfire = float(mu_backfire)\n",
        "        self.rep_edge_weight = float(rep_edge_weight)\n",
        "\n",
        "        # target opinion c*\n",
        "        if reference_opinion is None:\n",
        "            self.c_star = np.zeros(self.opinion_dim, dtype=np.float32)\n",
        "        else:\n",
        "            self.c_star = np.asarray(reference_opinion, dtype=np.float32).reshape(self.opinion_dim)\n",
        "\n",
        "        # spaces\n",
        "        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.num_voters, self.num_districts), dtype=np.float32)\n",
        "        # observation_space is symbolic; real obs is a PyG Data\n",
        "        self.observation_space = spaces.Dict({\n",
        "            \"x\": spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_voters, self.opinion_dim), dtype=np.float32),\n",
        "            \"y\": spaces.Box(low=0, high=self.num_districts-1, shape=(self.num_voters,), dtype=np.int64),\n",
        "        })\n",
        "\n",
        "        # state\n",
        "        self.t = 0\n",
        "        self._x = None\n",
        "        self._pos = None\n",
        "        self._edge_index = None\n",
        "        self._edge_attr = None\n",
        "        self._assignment = None\n",
        "        self._y = None\n",
        "        self._reps = None\n",
        "\n",
        "\n",
        "    def reset(self, seed: int | None = None, options: dict | None = None):\n",
        "        super().reset(seed=seed)\n",
        "        self.t = 0\n",
        "\n",
        "        if options is None:\n",
        "            raise ValueError(\"reset(options=...) must provide 'opinions', 'pos', and either 'edge_index' or 'social_adj'.\")\n",
        "\n",
        "        x = np.asarray(options[\"opinions\"], dtype=np.float32)\n",
        "        pos = np.asarray(options[\"pos\"], dtype=np.float32)\n",
        "        if x.shape != (self.num_voters, self.opinion_dim):\n",
        "            raise ValueError(\"opinions shape mismatch\")\n",
        "        if pos.shape != (self.num_voters, 2):\n",
        "            raise ValueError(\"pos must be (N,2)\")\n",
        "\n",
        "        if \"edge_index\" in options:\n",
        "            edge_index = np.asarray(options[\"edge_index\"], dtype=np.int64)\n",
        "            edge_attr = np.asarray(options.get(\"edge_attr\", np.ones(edge_index.shape[1])), dtype=np.float32)\n",
        "        else:\n",
        "            adj = np.asarray(options[\"social_adj\"], dtype=np.float32)\n",
        "            edge_index, edge_attr = self._adj_to_coo(adj)\n",
        "\n",
        "        assignment = options.get(\"assignment\", np.full((self.num_voters, self.num_districts),\n",
        "                                                      1.0 / self.num_districts, dtype=np.float32))\n",
        "        assignment = self._row_normalize(assignment)\n",
        "        assignment = self._ensure_non_empty_soft(assignment)\n",
        "\n",
        "        y = assignment.argmax(axis=1).astype(np.int64)\n",
        "        reps = self._elect_representatives_from_labels(y, x)\n",
        "\n",
        "        # state\n",
        "        self._x, self._pos = x, pos\n",
        "        self._edge_index, self._edge_attr = edge_index, edge_attr\n",
        "        self._assignment, self._y, self._reps = assignment, y, reps\n",
        "\n",
        "        return self.as_pyg_data(), {}\n",
        "\n",
        "\n",
        "    def step(self, action: np.ndarray):\n",
        "      assignment, y = self.mcmc_env(action, num_steps=10)\n",
        "\n",
        "      # Elect representatives based on final assignment\n",
        "      reps = self._elect_representatives_from_labels(y, self._x)\n",
        "      edge_index_aug, edge_attr_aug = self._augment_with_reps(self._edge_index, self._edge_attr, reps, y)\n",
        "\n",
        "      # Update opinions\n",
        "      x_new = self._opinion_update(edge_index_aug, edge_attr_aug, self._x)\n",
        "      reward = self._reward(self._x, x_new)\n",
        "\n",
        "      # Commit changes\n",
        "      self._assignment, self._y, self._reps = assignment, y, reps\n",
        "      self._x, self._edge_index, self._edge_attr = x_new, edge_index_aug, edge_attr_aug\n",
        "\n",
        "      self.t += 1\n",
        "      terminated = self.t >= self.horizon\n",
        "      return self.as_pyg_data(), float(reward), terminated, False, {}\n",
        "\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        mean = self._x.mean(axis=0)\n",
        "        print(f\"[t={self.t}] mean opinion ≈ {tuple(np.round(mean,3))}\")\n",
        "\n",
        "\n",
        "    def as_pyg_data(self) -> Data:\n",
        "        return Data(\n",
        "            x=torch.tensor(self._x, dtype=torch.float32),\n",
        "            y=torch.tensor(self._y, dtype=torch.long),\n",
        "            pos=torch.tensor(self._pos, dtype=torch.float32),\n",
        "            edge_index=torch.tensor(self._edge_index, dtype=torch.long),\n",
        "            edge_attr=torch.tensor(self._edge_attr, dtype=torch.float32),\n",
        "            assignment=torch.tensor(self._assignment, dtype=torch.float32),\n",
        "            reps=torch.tensor([r if r is not None else -1 for r in self._reps], dtype=torch.long),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _row_normalize(A: np.ndarray, eps=1e-8) -> np.ndarray:\n",
        "        row_sum = A.sum(axis=1, keepdims=True)\n",
        "        row_sum = np.clip(row_sum, eps, None)\n",
        "        return A / row_sum\n",
        "\n",
        "    def _ensure_non_empty_soft(self, A: np.ndarray) -> np.ndarray:\n",
        "        y = A.argmax(axis=1)\n",
        "        counts = np.bincount(y, minlength=self.num_districts)\n",
        "        for d in range(self.num_districts):\n",
        "            if counts[d] == 0:\n",
        "                donor = counts.argmax()\n",
        "                donor_nodes = np.where(y == donor)[0]\n",
        "                weakest = donor_nodes[np.argmin(A[donor_nodes, donor])]\n",
        "                A[weakest,:] = 0.0\n",
        "                A[weakest,d] = 1.0\n",
        "                y[weakest] = d\n",
        "                counts = np.bincount(y, minlength=self.num_districts)\n",
        "        return self._row_normalize(A)\n",
        "\n",
        "    @staticmethod\n",
        "    def _adj_to_coo(adj: np.ndarray):\n",
        "        row, col = np.nonzero(adj)\n",
        "        edge_index = np.vstack([row, col])\n",
        "        edge_attr = adj[row, col]\n",
        "        return edge_index, edge_attr\n",
        "\n",
        "    def _elect_representatives_from_labels(self, y: np.ndarray, X: np.ndarray):\n",
        "        reps = [None]*self.num_districts\n",
        "        dif = X[:,None,:] - X[None,:,:]\n",
        "        dists = np.linalg.norm(dif,axis=2)\n",
        "        for d in range(self.num_districts):\n",
        "            members = np.where(y==d)[0]\n",
        "            if len(members)==0: continue\n",
        "            sums = dists[np.ix_(members,members)].sum(axis=1)\n",
        "            reps[d] = int(members[np.argmin(sums)])\n",
        "        return reps\n",
        "\n",
        "    def _augment_with_reps(self, edge_index, edge_attr, reps, y):\n",
        "        add_src, add_dst, add_w = [], [], []\n",
        "        for d, r in enumerate(reps):\n",
        "            if r is None: continue\n",
        "            members = np.where(y==d)[0]\n",
        "            for v in members:\n",
        "                if v==r: continue\n",
        "                add_src.append(r)\n",
        "                add_dst.append(v)\n",
        "                add_w.append(self.rep_edge_weight)\n",
        "        if not add_src:\n",
        "            return edge_index, edge_attr\n",
        "        new_ei = np.concatenate([edge_index, np.vstack([add_src, add_dst])], axis=1)\n",
        "        new_ea = np.concatenate([edge_attr, np.array(add_w,dtype=np.float32)], axis=0)\n",
        "        return new_ei,new_ea\n",
        "\n",
        "    def _opinion_update(self, edge_index, edge_attr, X):\n",
        "        src,dst = edge_index\n",
        "        dif = X[src]-X[dst]\n",
        "        dist = np.linalg.norm(dif,axis=1)\n",
        "        gain = self._drf_gain(dist)\n",
        "        contrib = (gain*edge_attr)[:,None]*dif\n",
        "        delta = np.zeros_like(X)\n",
        "        np.add.at(delta,dst,contrib)\n",
        "        return X+self.eta*delta\n",
        "\n",
        "    def _drf_gain(self, d):\n",
        "        g=np.zeros_like(d,dtype=np.float32)\n",
        "        g[d<=self.a_thresh]=self.mu_assim\n",
        "        mid=(d>self.a_thresh)&(d<=self.b_thresh)\n",
        "        g[mid]=0.0\n",
        "        g[d>self.b_thresh]=self.mu_backfire\n",
        "        return g\n",
        "\n",
        "    def _reward(self, oldX,newX):\n",
        "        old_d=np.linalg.norm(oldX-self.c_star[None,:],axis=1).sum()\n",
        "        new_d=np.linalg.norm(newX-self.c_star[None,:],axis=1).sum()\n",
        "        return old_d-new_d\n",
        "\n",
        "    # In this approach, mcmc correct the assignment and return the opinion\n",
        "    def mcmc_env(self, action: np.ndarray, num_steps: int = 10, check_steps: int = 5):\n",
        "\n",
        "      current_assignment = self._row_normalize(action)\n",
        "      current_assignment = self._ensure_non_empty_soft(current_assignment)\n",
        "      current_y = current_assignment.argmax(axis=1)\n",
        "\n",
        "      reps = self._elect_representatives_from_labels(current_y, self._x)\n",
        "      edge_index_aug, edge_attr_aug = self._augment_with_reps(self._edge_index, self._edge_attr, reps, current_y)\n",
        "      x_new = self._opinion_update(edge_index_aug, edge_attr_aug, self._x)\n",
        "      current_reward = self._reward(self._x, x_new)\n",
        "\n",
        "      for _ in range(num_steps):\n",
        "          proposal = current_assignment.copy()\n",
        "          voter = self.rng.integers(0, self.num_voters)\n",
        "          new_d = self.rng.integers(0, self.num_districts)\n",
        "          proposal[voter,:] = 0\n",
        "          proposal[voter,new_d] = 1.0\n",
        "          proposal = self._row_normalize(proposal)\n",
        "          proposal = self._ensure_non_empty_soft(proposal)\n",
        "          proposal_y = proposal.argmax(axis=1)\n",
        "\n",
        "          check_assignment = proposal.copy()\n",
        "          check_y = proposal_y.copy()\n",
        "          check_reward = current_reward\n",
        "\n",
        "          for _ in range(check_steps):\n",
        "              temp = check_assignment.copy()\n",
        "              v = self.rng.integers(0, self.num_voters)\n",
        "              d = self.rng.integers(0, self.num_districts)\n",
        "              temp[v,:] = 0\n",
        "              temp[v,d] = 1.0\n",
        "              temp = self._row_normalize(temp)\n",
        "              temp = self._ensure_non_empty_soft(temp)\n",
        "              temp_y = temp.argmax(axis=1)\n",
        "\n",
        "              reps = self._elect_representatives_from_labels(temp_y, self._x)\n",
        "              edge_index_aug, edge_attr_aug = self._augment_with_reps(self._edge_index, self._edge_attr, reps, temp_y)\n",
        "              x_new = self._opinion_update(edge_index_aug, edge_attr_aug, self._x)\n",
        "              temp_reward = self._reward(self._x, x_new)\n",
        "\n",
        "              if temp_reward > check_reward:\n",
        "                  check_assignment, check_y, check_reward = temp, temp_y, temp_reward\n",
        "\n",
        "          if check_reward > current_reward:\n",
        "              current_assignment, current_y, current_reward = check_assignment, check_y, check_reward\n",
        "\n",
        "      return current_assignment, current_y\n"
      ],
      "metadata": {
        "id": "SVTh7C79jybC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 16\n",
        "K = 4\n",
        "T = 8\n",
        "\n",
        "opinions = np.linspace(-1,1,N)[:,None]\n",
        "opinions = np.hstack([opinions, np.zeros((N,1))])\n",
        "pos = np.arange(N)[:,None]\n",
        "pos = np.hstack([pos, np.zeros_like(pos)])\n",
        "\n",
        "edges = [(i,i+1) for i in range(N-1)]\n",
        "edge_index = np.array(edges + [(j,i) for i,j in edges]).T\n",
        "edge_attr = np.ones(edge_index.shape[1])\n",
        "\n",
        "env = FrankenmanderingEnv(num_voters=N, num_districts=K, opinion_dim=2, horizon=T)\n",
        "\n",
        "obs,_ = env.reset(options={\n",
        "    \"opinions\": opinions,\n",
        "    \"pos\": pos,\n",
        "    \"edge_index\": edge_index,\n",
        "    \"edge_attr\": edge_attr\n",
        "})\n",
        "\n",
        "for t in range(T):\n",
        "    action = np.ones((N,K), dtype=np.float32)/K\n",
        "    obs, reward, done, _, _ = env.step(action)\n",
        "    print(f\"t={t}, reward={reward:.3f}, mean opinion={obs.x.mean(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfdFfrmcG6ht",
        "outputId": "2fb505ee-a3ba-42e7-86db-43ac0bc19002"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=0, reward=0.347, mean opinion=tensor([0.0017, 0.0000])\n",
            "t=1, reward=0.597, mean opinion=tensor([-0.0037,  0.0000])\n",
            "t=2, reward=0.553, mean opinion=tensor([-0.0097,  0.0000])\n",
            "t=3, reward=0.456, mean opinion=tensor([-0.0176,  0.0000])\n",
            "t=4, reward=0.584, mean opinion=tensor([-0.0272,  0.0000])\n",
            "t=5, reward=0.501, mean opinion=tensor([-0.0254,  0.0000])\n",
            "t=6, reward=0.084, mean opinion=tensor([-0.0137,  0.0000])\n",
            "t=7, reward=0.233, mean opinion=tensor([-0.0111,  0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cttpLix5rA_J"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}