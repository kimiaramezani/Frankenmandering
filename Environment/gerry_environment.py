# -*- coding: utf-8 -*-
"""Gerry_Environment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12kp7EO3sSjg3hc-TPKlBY6Y_mzoS37yK

##**Gerrymandering-Environment**

    INITIAL STATE (provided externally via reset(options=...)):
        - 'district_map'
        - 'social_graph'
        - 'opinions'     

    ACTION:
        - new district assignment for each voter

    OBSERVATION (returned by reset/step):
        {
          'district_map'   : (num_voters,)
          'representatives': (num_districts,)  # voter indices; -1 if empty district
          'social_graph'   : (num_voters, num_voters)  # AUGMENTED: base social + rep->voter edges used for the step
          'opinions'       : (num_voters, 2)
          'opinion_graph'  : (num_voters, num_voters)  # similarity kernel derived from opinion distances
        }

    KEY LOGIC:
      - Representatives: for each district, pick the member that minimizes the sum of L2 distances to members in that district (discrete 1-median).
      - Opinion dynamics: DRF (assimilation/neutral/backfire) with weighted neighbor influence.
      - Reward: reduction in total distance to reference opinion c*

    Notes:
      - Opinion weight = 1
      - Opinion dimension is fixed at 2.
      - We accept any districting action
"""

!pip install torch_geometric

import numpy as np
import torch
from torch_geometric.data import Data
import gymnasium as gym
from gymnasium import spaces

class FrankenmanderingEnv(gym.Env):

    metadata = {"render_modes": ["human"]}

    def __init__(
        self,
        num_voters: int,
        num_districts: int,
        opinion_dim: int = 2,
        horizon: int = 10,
        seed: int | None = None,
        # reward target
        reference_opinion: np.ndarray | None = None,
    ):
        super().__init__()
        self.num_voters = int(num_voters)
        self.num_districts = int(num_districts)
        self.opinion_dim = int(opinion_dim)
        self.horizon = int(horizon)
        self.rng = np.random.default_rng(seed)
        # self.rep_edge_weight = float(rep_edge_weight)

        # target opinion c*
        if reference_opinion is None:
            self.c_star = np.zeros(self.opinion_dim, dtype=np.float32)
        else:
            self.c_star = np.asarray(reference_opinion, dtype=np.float32).reshape(self.num_voters,self.opinion_dim)

        # spaces
        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.num_voters, self.num_districts), dtype=np.float32)

        # observation_space is symbolic; real obs is a PyG Data
        self.observation_space = spaces.Dict({
            "x": spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_voters, self.opinion_dim), dtype=np.float32),
            "y": spaces.Box(low=0, high=self.num_districts-1, shape=(self.num_voters,), dtype=np.int64),
        })

        # state
        self.t = 0
        self._x = None
        self._pos = None
        self._edge_index = None
        self._edge_attr = None
        self._assignment = None
        self._y = None
        self._reps = None


    def reset(self, seed: int | None = None, options: dict | None = None):
        super().reset(seed=seed)
        self.t = 0

        if options is None:
            raise ValueError("reset(options=...) must provide 'opinions', 'pos', and either 'edge_index' or 'social_adj'.")

        x = np.asarray(options["opinions"], dtype=np.float32)
        # print(x)
        # print(x.shape)
        pos = np.asarray(options["pos"], dtype=np.float32)
        if x.shape != (self.num_voters, self.opinion_dim):
            raise ValueError("opinions shape mismatch")
        if pos.shape != (self.num_voters, 2):
            raise ValueError("pos must be (N,2)")

        if "edge_index" in options:
            edge_index = np.asarray(options["edge_index"], dtype=np.int64)
            edge_attr = np.asarray(options.get("edge_attr", np.ones(edge_index.shape[1])), dtype=np.float32)
        else:
            adj = np.asarray(options["social_adj"], dtype=np.float32)
            edge_index, edge_attr = self._adj_to_coo(adj)

        assignment = options.get("assignment", np.full((self.num_voters, self.num_districts),
                                                      1.0 / self.num_districts, dtype=np.float32))
        assignment = self._row_normalize(assignment)
        assignment = self._ensure_non_empty(assignment)

        y = assignment.argmax(axis=1).astype(np.int64)
        reps = self._elect_representatives_from_labels(y, x)

        self._x, self._pos = x, pos
        self._edge_index, self._edge_attr = edge_index, edge_attr
        self._assignment, self._y, self._reps = assignment, y, reps

        edge_index_aug, edge_attr_aug = self._augment_with_reps(edge_index, edge_attr, reps, y)

        return self.as_pyg_data(edge_index_aug, edge_attr_aug), {}


    def step(self, action: np.ndarray):
        assignment = np.asarray(action, dtype=np.float32)
        assignment = self._row_normalize(assignment)
        assignment = self._ensure_non_empty(assignment)

        y = assignment.argmax(axis=1).astype(np.int64)
        reps = self._elect_representatives_from_labels(y, self._x)

        edge_index_aug, edge_attr_aug = self._augment_with_reps(self._edge_index, self._edge_attr, reps, y)
        x_new = self._opinion_update(edge_index_aug, edge_attr_aug, self._x)
        reward = self._reward(self._x, x_new)

        # commit
        # self._assignment, self._y, self._reps = assignment, y, reps
        # self._x, self._edge_index, self._edge_attr = x_new, edge_index_aug, edge_attr_aug

        self._assignment, self._y, self._reps = assignment, y, reps
        self._x = x_new

        self.t += 1
        terminated = self.t >= self.horizon
        return self.as_pyg_data(edge_index_aug, edge_attr_aug), float(reward), terminated, False, {}

    def render(self, mode="human"):
        mean = self._x.mean(axis=0)
        print(f"[t={self.t}] mean opinion ≈ {tuple(np.round(mean,3))}")


    def as_pyg_data(self, edge_index=None, edge_attr=None) -> Data:
      if edge_index is None:
          edge_index = self._edge_index
      if edge_attr is None:
          edge_attr = self._edge_attr

      return Data(
          x=torch.tensor(self._x, dtype=torch.float32),
          y=torch.tensor(self._y, dtype=torch.long),
          pos=torch.tensor(self._pos, dtype=torch.float32),
          edge_index=torch.tensor(edge_index, dtype=torch.long),
          edge_attr=torch.tensor(edge_attr, dtype=torch.float32),
          assignment=torch.tensor(self._assignment, dtype=torch.float32),
          reps=torch.tensor([r if r is not None else -1 for r in self._reps], dtype=torch.long),
      )

    @staticmethod
    def _row_normalize(A: np.ndarray, eps=1e-8) -> np.ndarray:
        row_sum = A.sum(axis=1, keepdims=True)
        row_sum = np.clip(row_sum, eps, None)
        return A / row_sum

    def _ensure_non_empty(self, A: np.ndarray) -> np.ndarray:
      y = A.argmax(axis=1)
      A_hard = np.zeros_like(A)
      A_hard[np.arange(len(y)), y] = 1.0
      counts = np.bincount(y, minlength=self.num_districts)
      for d in range(self.num_districts):
          if counts[d] == 0:
              donor = counts.argmax()
              donor_nodes = np.where(y == donor)[0]
              weakest = donor_nodes[np.argmin(A[donor_nodes, donor])]
              A_hard[weakest, :] = 0.0
              A_hard[weakest, d] = 1.0
              y[weakest] = d
              counts = np.bincount(y, minlength=self.num_districts)
      return A_hard


    @staticmethod
    def _adj_to_coo(adj: np.ndarray):
        row, col = np.nonzero(adj)
        edge_index = np.vstack([row, col])
        edge_attr = adj[row, col]
        return edge_index, edge_attr

    def _elect_representatives_from_labels(self, y: np.ndarray, X: np.ndarray):
        reps = [None]*self.num_districts
        dif = X[:,None,:] - X[None,:,:]
        dists = np.linalg.norm(dif,axis=2)
        for d in range(self.num_districts):
            members = np.where(y==d)[0]
            if len(members)==0: continue
            sums = dists[np.ix_(members,members)].sum(axis=1)
            reps[d] = int(members[np.argmin(sums)])
        return reps

    def _augment_with_reps(self, edge_index, edge_attr, reps, y,  rep_edge_weight: float = 1.0):
        add_src, add_dst, add_w = [], [], []
        for d, r in enumerate(reps):
            if r is None: continue
            members = np.where(y==d)[0]
            for v in members:
                if v==r: continue
                add_src.append(r)
                add_dst.append(v)
                add_w.append(rep_edge_weight)
        if not add_src:
            return edge_index, edge_attr
        new_ei = np.concatenate([edge_index, np.vstack([add_src, add_dst])], axis=1)
        new_ea = np.concatenate([edge_attr, np.array(add_w,dtype=np.float32)], axis=0)
        return new_ei,new_ea

    def _opinion_update(self, edge_index, edge_attr, X, eta=1.0):
      src, dst = edge_index
      dif = X[src] - X[dst]
      dist = np.abs(dif).flatten()

      gain = self._drf_gain(dist)
      contrib = (gain * edge_attr)[:, None] * np.sign(dif)  # ±1 step
      delta = np.zeros_like(X)
      np.add.at(delta, dst, contrib)
      return X + eta * delta


    def _drf_gain(self, d, thresh=3.0):
      g = np.zeros_like(d, dtype=np.float32)
      g[d < thresh] = 1.0    # assimilation
      g[d >= thresh] = -1.0  # backfire
      return g


    def _reward(self, oldX,newX):
        old_d=np.linalg.norm(oldX-self.c_star,axis=1).sum()
        new_d=np.linalg.norm(newX-self.c_star,axis=1).sum()
        return old_d-new_d

