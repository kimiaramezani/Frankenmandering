# -*- coding: utf-8 -*-
"""Gerry_Environment_26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aPwJZYE_PhRLl1xPuATCljvvKNmquLZp
"""

# !pip install torch_geometric

"""##**Gerrymandering-Environment**

    INITIAL STATE (provided externally via reset(options=...)):
        - 'district_map'
        - 'social_graph'
        - 'opinions'     

    ACTION:
        - new district assignment for each voter

    OBSERVATION (returned by reset/step):
        {
          'district_map'   : (num_voters,)
          'representatives': (num_districts,)  # voter indices; -1 if empty   district
          'social_graph'   : (num_voters, num_voters)  # AUGMENTED: base social + rep->voter edges used for the step
          'opinions'       : (num_voters, 2)
          'opinion_graph'  : (num_voters, num_voters)  # similarity kernel derived from opinion distances
        }

    KEY LOGIC:
      - Representatives: for each district, pick the member that minimizes the sum of L2 distances to members in that district (discrete 1-median).
      - Opinion dynamics: DRF (assimilation/neutral/backfire) with weighted neighbor influence.
      - Reward: reduction in total distance to reference opinion c*

#This is the Frankenmandering Data class which includes:
*   social edge list: type: matrix and size : (v,v)
*   assignment edge list: type: matrix and size:(v,d)
*   number of orignin edge
*   geometric position
*   district label
*   edge attribute
*   representative
*   opinion
"""



import numpy as np
import torch
from torch_geometric.data import Data
import gymnasium as gym
from gymnasium import spaces
import copy
from typing import Optional, Tuple, Dict, Any
import math
from helpers_functions import *

class FrankenData(Data):
    def __init__(self, social_edge, geographical_edge, orig_edge_num,
                 opinion, pos, reps, dist_label, edge_attr, geo_edge_attr, **kwargs):
        super().__init__(**kwargs)
        self.orig_edge_num = int(orig_edge_num)
        self.opinion = torch.as_tensor(opinion, dtype=torch.float32)
        self.pos = torch.as_tensor(pos, dtype=torch.float32)
        self.dist_label = torch.as_tensor(dist_label, dtype=torch.long)
        self.social_edge = torch.as_tensor(social_edge, dtype=torch.long)
        self.edge_attr = torch.as_tensor(edge_attr, dtype=torch.float32)

        # handle optional geographical edges safely
        self.geographical_edge = (
            torch.as_tensor(geographical_edge, dtype=torch.long)
            if geographical_edge is not None else None
        )
        self.geo_edge_attr = (
            torch.as_tensor(geo_edge_attr, dtype=torch.float32)
            if geo_edge_attr is not None else None
        )

        self.reps = reps

        # preserve any additional kwargs
        for k, v in kwargs.items():
            setattr(self, k, v)

    # instance method for saving
    def save(self, file_path: str):
        torch.save(self, file_path)
        print(f"FrankenData object saved to {file_path}")

    # class method for loading
    @classmethod
    def load(cls, file_path: str):
        data = torch.load(file_path)
        if not isinstance(data, cls):
            raise TypeError(f"Loaded object is not a {cls.__name__} instance.")
        print(f"FrankenData object loaded from {file_path}")
        return data

class FrankenmanderingEnv(gym.Env):

    metadata = {"render_modes": ["human"]}

    def __init__(
        self,
        num_voters: int,
        num_districts: int,
        opinion_dim: int = 2,
        horizon: int = 10,
        seed: int | None = None,
        FrankenData = None,
        # target
        target_opinion: np.ndarray | None = None

    ):
        super().__init__()
        self.num_voters = int(num_voters)
        self.num_districts = int(num_districts)
        self.opinion_dim = int(opinion_dim)
        self.horizon = int(horizon)
        self.rng = np.random.default_rng(seed)

        self.t = 0
        self.initial_data = copy.deepcopy(FrankenData)
        self.FrankenData = FrankenData
        self.opinion_update_step = 0

        self.transition_history = []
        self.committed_state = None

        # target opinion c*
        if target_opinion is None:
            self.c_star = np.zeros((self.num_voters,self.opinion_dim), dtype=np.float32)
        else:
            self.c_star = np.asarray(target_opinion, dtype=np.float32).reshape(self.num_voters,self.opinion_dim)

        # action spaces
        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.num_voters, self.num_districts), dtype=np.float32)

        self.observation_space = spaces.Dict({
                  "opinions": spaces.Box(low=-np.inf, high=np.inf,
                                        shape=(self.num_voters, self.opinion_dim), dtype=np.float32),

                  "positions": spaces.Box(low=-np.inf, high=np.inf,
                                          shape=(self.num_voters, 2), dtype=np.float32),

                  "dist_label": spaces.Box(low=0, high=self.num_districts-1,
                                          shape=(self.num_voters,), dtype=np.int32),

                  "reps": spaces.Box(low=-1, high=self.num_voters-1,
                                    shape=(self.num_districts,), dtype=np.int32),

                  "social_edge_index": spaces.Box(low=0, high=self.num_voters-1,
                                shape=(2, self.initial_data.orig_edge_num), dtype=np.int32),

                  "social_edge_attr": spaces.Box(low=0, high=np.inf,
                                                shape=(self.initial_data.orig_edge_num,), dtype=np.float32),

                  "assignment": spaces.Box(low=0, high=1,
                                          shape=(self.num_voters, self.num_districts), dtype=np.int32),
              })


    # options includes opinions, geometric position,  edge_index(social graph,assignment),assignment
    def reset(self, seed: int | None = None, options: dict | None = None):
        super().reset(seed=seed)
        self.t = 0

        self.FrankenData = copy.deepcopy(self.initial_data)
        self.transition_history = []
        self.committed_state = self.initial_data

        return self.FrankenData, {}

    def step(self, action: np.ndarray, DRF,Beta1,Beta2):

        if self.FrankenData is None:
            raise RuntimeError("Environment must be reset before calling step.")

        # Normalize action and compute new assignment
        assignment = row_normalize(np.asarray(action, dtype=np.float32))

        # assignment = ensure_non_empty(assignment)
        dist_label = assignment.argmax(axis=1).astype(np.int32)
        # dist_label[(assignment.max(axis=1) == 0)] = -1

        # Elect new representatives
        reps = elect_representatives(dist_label, self.FrankenData.opinion, self.num_districts)
        #partial reset augmented graph
        social_graph = self.FrankenData.social_edge[:, :self.FrankenData.orig_edge_num]

        social_edge_attr = self.FrankenData.edge_attr[:self.FrankenData.orig_edge_num]

        # update social graph based on reps and new assignment
        aug_edge_index, aug_edge_attr = augment_with_reps(
            social_graph,
            social_edge_attr,
            reps,
            dist_label
        )

        # Update oppinion
        x_new = opinion_update(aug_edge_index, aug_edge_attr,self.FrankenData.opinion, DRF )

        reward = self.reward(self.FrankenData.opinion, x_new, dist_label, self.FrankenData.geographical_edge,Beta1,Beta2)

        self.t += 1
        self.opinion_update_step +=1
        terminated = self.t >= self.horizon

        self.FrankenData = FrankenData(
              social_edge = aug_edge_index,
              orig_edge_num = self.initial_data.orig_edge_num,
              geographical_edge= self.initial_data.geographical_edge,
              opinion= x_new,
              pos =self.FrankenData.pos,
              reps=[r if r is not None else -1 for r in reps],
              dist_label=dist_label,
              edge_attr = aug_edge_attr,
              geo_edge_attr= self.initial_data.geo_edge_attr
            )
        self.transition_history.append(self.FrankenData)

        return self.FrankenData, float(reward), terminated, False, {}

    def reward(self, old_opinion,new_opinion, dist_label, geo_edge, Beta1,Beta2):
        # check the population equity and compactness constraints
        pop_dev = population_equality(np.ones_like(dist_label),dist_label, self.num_districts)
        comp_score = compactness_score(geo_edge, dist_label)

        penalty =  -Beta1 * pop_dev - Beta2 * comp_score

        old_d=np.linalg.norm(old_opinion-self.c_star,axis=1).sum()
        new_d=np.linalg.norm(new_opinion-self.c_star,axis=1).sum()

        reward = penalty + old_d-new_d
        return reward

    def commit(self):

      self.committed_state = self.transition_history[-1]
      self.transition_history.clear()
      self.transition_history.append(self.committed_state)

      return self.transition_history